{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineární klasifikace do více tříd pomocí funkce Softmax\n",
    "\n",
    "Úloha zaměřená na implementaci paralelního lineární klasifikáru pomocí funkce softmax.\n",
    "\n",
    "\n",
    "### Softmax\n",
    "- Funkce softmax má c vstupů a c výstupů. \n",
    "- Všechny výstupy jsou kladná čísla. \n",
    "- Součet všech výstupů dohromady je roven číslu 1.\n",
    "$$\\widehat{y_c} = softmax(u) = \\frac{e^{u_c}}{\\sum_{d=0}^{c} {e^{u_d}}} $$\n",
    "\n",
    "Výsledkem klasifikace je třída, pro kterou je hodnota softmaxu nejvyšší.\n",
    "\n",
    "### Odhad parametrů modelu\n",
    "\n",
    "Model nemá jeden vektor parametrů $\\theta$, ale matici parametrů $\\Theta$\n",
    "\n",
    "Příklad:\n",
    "- Vektor $x$ má dimenzi 3 (3 příznaky)\n",
    "- Klasifikujeme do 4 tříd\n",
    "$$ \\Theta^T = \n",
    "        \\begin{bmatrix}\n",
    "        [\\theta_{00} & \\theta_{01} & \\theta_{02} & \\theta_{03}] \\\\\n",
    "        [\\theta_{10} & \\theta_{11} & \\theta_{12} & \\theta_{13}] \\\\\n",
    "        [\\theta_{20} & \\theta_{21} & \\theta_{22} & \\theta_{23}] \\\\\n",
    "        [\\theta_{30} & \\theta_{31} & \\theta_{32} & \\theta_{33}] \\\\\n",
    "        \\end{bmatrix}  $$\n",
    "\n",
    "#### Pomoc sumy:\n",
    "\n",
    "$$ \\Theta_{t+1} = \\Theta_{t} - \\alpha \\sum_{i=0}^{N} {x_i}^T (\\widehat{y_i} - y_i) $$\n",
    "kde $\\alpha$ je velikost kroku (learning rate), \n",
    "\n",
    "$y_i$ je vektor, obsahující hodnotu 1 na indexu správné třídy: $y_i \\in [...0, 0, 1, 0,..]$,\n",
    "\n",
    "$\\widehat{y_i} = softmax(x_i^T \\Theta)^T$\n",
    "\n",
    "\n",
    "#### Pomocí  matice:\n",
    "Maticová implementace je řádově výpočetně efektivnější.\n",
    "\n",
    "$$ \\Theta_{t+1} = \\Theta_{t} - \\alpha X^T (\\widehat{Y} - Y) $$\n",
    "$Y$ je matice nul a jedniček dle indexů tříd v datech (one_hot_encoding), \n",
    "\n",
    "#### Postup:\n",
    "1. Parametr $\\theta$ (resp. váhy $w$ a bias $b$) se inicializuje na malé náhodné hodnoty\n",
    "2. Na vstup se přivedou všechna trénovací data a na výstupu se tím pádem objeví posloupnost nul a jedniček (obsahuje chyby)\n",
    "3. Na základě chyb se upraví hodnoty vah\n",
    "4. Kroky 2. a 3. se postupně opakují dokud dostatečně klesá chybovost klasifikátoru (nebo podle počtu iteraci)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikace pro 2 třídy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import usu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_loss(iterations, loss, epoch=False):\n",
    "    plt.plot(iterations, loss)\n",
    "    plt.xlabel(\"Epocha\" if epoch else \"Iterace\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Průběh trénování\")\n",
    "    plt.show()\n",
    "\n",
    "npzfile = np.load('data/data_07_2cl.npz')\n",
    "\n",
    "data = npzfile['data']\n",
    "ref = npzfile['ref']\n",
    "data.shape, ref.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usu.drawSoftmax(data,ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(u):\n",
    "    \"\"\"\n",
    "    vstupem muze byt skalar, vektor, nebo matice \n",
    "    \"\"\"\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "\n",
    "    # Numerical stability: subtract max value to prevent overflow\n",
    "    u_shifted = u - np.max(u, axis=0, keepdims=True)\n",
    "    exp_u = np.exp(u_shifted)\n",
    "    y = exp_u / np.sum(exp_u, axis=0, keepdims=True)\n",
    "    \n",
    "    #################################################################\n",
    "    return y\n",
    "\n",
    "usu.checkSoftmax(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeThetaGD(x, y, alpha=0.01, iterations=1000, plot_loss=False):\n",
    "    # pro kazdou iteraci vypoctete loss a zapiste ho na odpovidajici index v promenne\n",
    "    loss = np.zeros(iterations)\n",
    "\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "\n",
    "    # Flatten y if needed (handle both (N,) and (N,1) shapes)\n",
    "    y = y.flatten()\n",
    "    \n",
    "    # Get number of samples and features\n",
    "    n_samples = x.shape[0]\n",
    "    n_features = x.shape[1]\n",
    "    n_classes = np.max(y) + 1\n",
    "    \n",
    "    # Add bias term to x\n",
    "    X = np.c_[np.ones(n_samples), x]\n",
    "    \n",
    "    # Initialize theta with small random values\n",
    "    theta = np.random.randn(n_features + 1, n_classes) * 0.01\n",
    "    \n",
    "    # One-hot encode the target classes\n",
    "    Y = np.zeros((n_samples, n_classes))\n",
    "    Y[np.arange(n_samples), y] = 1\n",
    "    \n",
    "    # Gradient descent iterations\n",
    "    for iteration in range(iterations):\n",
    "        # Compute predictions using softmax\n",
    "        u = X @ theta  # Linear combination\n",
    "        Y_pred = softmax(u.T).T  # Apply softmax row-wise\n",
    "        \n",
    "        # Compute gradient\n",
    "        gradient = X.T @ (Y_pred - Y)\n",
    "        \n",
    "        # Update theta\n",
    "        theta = theta - alpha * gradient\n",
    "        \n",
    "        # Compute loss (cross-entropy)\n",
    "        loss[iteration] = -np.sum(Y * np.log(Y_pred + 1e-15)) / n_samples\n",
    "    \n",
    "    #################################################################\n",
    "\n",
    "    if plot_loss:\n",
    "        show_loss(np.arange(iterations), loss)\n",
    "\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = computeThetaGD(data, ref, plot_loss=True)\n",
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([[ 9.10851553, -9.10851553],\n",
    "       [-3.01430677,  3.01430677],\n",
    "       [-2.90413336,  2.90413336]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usu.drawSoftmax(data, ref, theta, softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,theta):\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    # Add bias term to x\n",
    "    X = np.c_[np.ones(x.shape[0]), x]\n",
    "    \n",
    "    # Compute linear combination\n",
    "    u = X @ theta\n",
    "    \n",
    "    # Apply softmax and get predicted classes\n",
    "    y_prob = softmax(u.T).T\n",
    "    classes = np.argmax(y_prob, axis=1)\n",
    "    #################################################################\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array([[1, 1],[ 2, 2]])\n",
    "predict(x_pred,theta)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([0, 1], dtype=int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikace pro více tříd:\n",
    "#### 3 třídy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data/data_07_3cl_ez.npz') \n",
    "\n",
    "data = npzfile['data']\n",
    "ref = npzfile['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = computeThetaGD(data, ref, plot_loss=True)\n",
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([[ 5.07711635e-01, -5.03105973e-01, -4.60566172e-03],\n",
    "       [ 2.72038774e+00,  5.91185553e+00, -8.63224327e+00],\n",
    "       [-7.47227524e+00,  4.70478069e+00,  2.76749455e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usu.drawSoftmax(data, ref, theta, softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array([[-3, 1],[ 0, -2],[ 3, 2]])\n",
    "predict(x_pred,theta)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([2, 0, 1], dtype=int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 třídy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data/data_07_4cl.npz')\n",
    "\n",
    "data = npzfile['data']\n",
    "ref = npzfile['ref']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = computeThetaGD(data, ref, plot_loss=True)\n",
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([[-1.69592530e-04,  1.78920810e-04,  2.52757259e-05,\n",
    "        -3.46040058e-05],\n",
    "       [ 8.17559935e+00,  6.92671210e+00, -7.25371298e+00,\n",
    "        -7.84859846e+00],\n",
    "       [-6.79704211e+00,  6.90764576e+00, -7.30088112e+00,\n",
    "         7.19027748e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usu.drawSoftmax(data, ref, theta, softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array([[-3, -1],[ -3, 2],[ 3, -1],[ 3, 2]])\n",
    "predict(x_pred,theta)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([2, 3, 0, 1], dtype=int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 tříd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data/data_07_5cl.npz')\n",
    "\n",
    "data = npzfile['data']\n",
    "ref = npzfile['ref']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = computeThetaGD(data, ref, plot_loss=True)\n",
    "theta"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([[-2.48175733, -3.17075268, -3.11566359, -2.61417318, 11.38234678],\n",
    "       [ 7.25756266,  6.37331542, -6.94692967, -6.42019195, -0.26375646],\n",
    "       [-5.6309561 ,  6.33801352, -6.94636603,  6.31988487, -0.08057625]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usu.drawSoftmax(data, ref, theta, softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.array([[-3, -1],[ -3, 2],[ 3, -1],[ 3, 2],[0, 0]])\n",
    "predict(x_pred,theta)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pro kontrolu správnosti:\n",
    "array([2, 3, 0, 1, 4], dtype=int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Rozpoznávání číslovek (MNIST database) a mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dosáhněte accuracy (vypočtené na konci) alespoň 91 %.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data/data_07_mnist_train.npz') \n",
    "\n",
    "data = npzfile['data']\n",
    "ref = npzfile['ref']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prohlédněte si prvních 20 trénovacích vzorků:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(20):\n",
    "    # Prevedeni linearizovych dat zpet na 2D matici.\n",
    "    img = np.reshape(data[i], (28, 28))\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(img, \"gray_r\")\n",
    "    plt.title(ref[i])\n",
    "    plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naimplementuje trénování modelu pomocí mini-batch gradient descent:\n",
    "\n",
    "Mini-batch gradient descent vzhledem k množství dat zefektivní trénování (model se natrénuje rychleji a lépe zobecňuje).\n",
    "\n",
    "Vyjděte z předchozí implementace `computeThetaGD` a upravte ji.\n",
    "\n",
    "Počet iterací (u GD ekvivalentní průchodu všemi testovacími daty) bude nahrazen počtem tzv. epoch.\n",
    "\n",
    "Jedna epocha probíhá následovně:\n",
    "- Na začátku se náhodně zamíchají testovací data.\n",
    "- Všechna testovací data se projdou po mini-batchích, jejichž délka je vždy rovna zadané `batch_size`. Na základě každého mini-batche se aktualizují váhy (u `computeThetaGD` se aktualizovaly váhy na základě všech dat). Pokud by na konci epochy zbyly vzorky, jejichž počet už je menší než `batch_size`, tak se přeskočí.\n",
    "- Na konci epochy se spočítá loss na základě všech dat pro vizualizaci.\n",
    "\n",
    "TIP: Vhodně normalizujte úpravu vah, aby její výsledná velikost nezávisela na `batch_size` a parametry `alpha` a `batch_size` jste mohli ladit nezávisle na sobě."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeThetaSGD(x, y, *, alpha, epochs, batch_size, plot_loss=False):\n",
    "    # zafixovani nahody pri trenovani\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # na konci kazde epochy vypoctete loss (ze vsech trenovacich vzorku) a zapiste ho na odpovidajici index v promenne\n",
    "    loss = np.zeros(epochs)\n",
    "\n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "\n",
    "    # Flatten y if needed (handle both (N,) and (N,1) shapes)\n",
    "    y = y.flatten()\n",
    "    \n",
    "    # Get number of samples, features, and classes\n",
    "    n_samples = x.shape[0]\n",
    "    n_features = x.shape[1]\n",
    "    n_classes = np.max(y) + 1\n",
    "    \n",
    "    # Add bias term to x\n",
    "    X = np.c_[np.ones(n_samples), x]\n",
    "    \n",
    "    # Initialize theta with small random values\n",
    "    theta = np.random.randn(n_features + 1, n_classes) * 0.01\n",
    "    \n",
    "    # One-hot encode the target classes\n",
    "    Y = np.zeros((n_samples, n_classes))\n",
    "    Y[np.arange(n_samples), y] = 1\n",
    "    \n",
    "    # Mini-batch gradient descent\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle data at the beginning of each epoch\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        X_shuffled = X[indices]\n",
    "        Y_shuffled = Y[indices]\n",
    "        \n",
    "        # Process mini-batches\n",
    "        for i in range(0, n_samples - batch_size + 1, batch_size):\n",
    "            # Get mini-batch\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            Y_batch = Y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            # Compute predictions using softmax\n",
    "            u = X_batch @ theta\n",
    "            Y_pred = softmax(u.T).T\n",
    "            \n",
    "            # Compute gradient and normalize by batch_size\n",
    "            gradient = X_batch.T @ (Y_pred - Y_batch) / batch_size\n",
    "            \n",
    "            # Update theta\n",
    "            theta = theta - alpha * gradient\n",
    "        \n",
    "        # Compute loss on all training data at the end of epoch\n",
    "        u_all = X @ theta\n",
    "        Y_pred_all = softmax(u_all.T).T\n",
    "        loss[epoch] = -np.sum(Y * np.log(Y_pred_all + 1e-15)) / n_samples\n",
    "    \n",
    "    #################################################################\n",
    "\n",
    "    if plot_loss:\n",
    "        show_loss(np.arange(epochs), loss, epoch=True)\n",
    "\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ZDE DOPLNIT hodnoty hyperparametrů (dostatečný model lze natrénovat během 5-10 sekund)\n",
    "theta = computeThetaSGD(data, ref, batch_size=128, epochs=50, alpha=0.1, plot_loss=True)\n",
    "#################################################################\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prohlédněte si natrénované váhy (s výjimkou biasu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(theta.shape[1]):\n",
    "    # Prvni vaha je bias, zbytek odpovida bodum v obrazu, takze je preskupime na 2D obraz.\n",
    "    img = np.reshape(theta.T[i][1:], (28, 28))\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img, \"gray_r\")\n",
    "    plt.title(str(i))\n",
    "    plt.axis(\"off\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('data/data_07_mnist_test.npz') \n",
    "\n",
    "test_data = npzfile['data']\n",
    "test_ref = npzfile['ref']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otestujte prvních 20 testovacích vzorků:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "x = test_data[:n, :]\n",
    "y = test_ref[:n]\n",
    "\n",
    "#################################################################\n",
    "# ZDE DOPLNIT - Zjistete predikovane tridy pro `x`\n",
    "\n",
    "y_pred = predict(x, theta)\n",
    "\n",
    "#################################################################\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n):\n",
    "    # Prevedeni linearizovych dat zpet na 2D matici.\n",
    "    img = np.reshape(x[i, :], (28, 28))\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.imshow(img, \"gray_r\")\n",
    "    plt.title(f\"predicted: {y_pred[i]}\\nactual: {y[i]}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy – přesnost natrénovaného modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT - Zjistete predikovane tridy pro vsechna testovaci data a procento spravne predikovanych dat (accuracy).\n",
    "\n",
    "test_pred = predict(test_data, theta)\n",
    "accuracy = np.mean(test_pred == test_ref)\n",
    "\n",
    "#################################################################\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navíc: všimněte si, jak se mění grafy vah, když zvyšujete/snižujete batch size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2511_vsu_sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
